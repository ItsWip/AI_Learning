{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de54d270-81bf-422a-aeb8-f1e83f2153d2",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "from IPython.display import display, HTML\n",
    "from helper import extract_html_content\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61267ae9-a841-47f1-9584-437fd1be5816",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0046334c-404b-4c44-abcd-7cc1c8e0e4cb",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ccb487-d089-4ac2-844a-4b3bc0f5e223",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ff32431-3ae4-446a-a458-c40949ef6f4f",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4ec7c0bb-a320-4fe5-98de-1d6c2942d332\n"
     ]
    }
   ],
   "source": [
    "documents = LlamaParse(\n",
    "    api_key=llama_cloud_api_key,\n",
    "    base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "    result_type=\"markdown\",\n",
    "    content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    ").load_data(\n",
    "    \"data/fake_resume.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1245b406-c0ff-42b8-9498-cb14e2f729bf",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Projects\n",
      "\n",
      "# EcoTrack | GitHub\n",
      "\n",
      "- Built full-stack application for tracking carbon footprint using React, Node.js, and MongoDB\n",
      "- Implemented machine learning algorithm for providing personalized sustainability recommendations\n",
      "- Featured in TechCrunch's \"Top 10 Environmental Impact Apps of 2023\"\n",
      "\n",
      "# ChatFlow | Demo\n",
      "\n",
      "- Developed real-time chat application using WebSocket protocol and React\n",
      "- Implemented end-to-end encryption and message persistence\n",
      "- Serves 5000+ monthly active users\n",
      "\n",
      "# Certifications\n",
      "\n",
      "- AWS Certified Solutions Architect (2023)\n",
      "- Google Cloud Professional Developer (2022)\n",
      "- MongoDB Certified Developer (2021)\n",
      "\n",
      "# Languages\n",
      "\n",
      "- English (Native)\n",
      "- Mandarin Chinese (Fluent)\n",
      "- Spanish (Intermediate)\n",
      "\n",
      "# Interests\n",
      "\n",
      "- Open source contribution\n",
      "- Tech blogging (15K+ Medium followers)\n",
      "- Hackathon mentoring\n",
      "- Rock climbing\n"
     ]
    }
   ],
   "source": [
    "print(documents[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d6351c-9e1f-457b-b6d0-d739fb826743",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b6b96c5-82a7-4c9f-9e8d-300806533340",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\", \n",
    "                                api_key= openai_api_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956a7e3b-7861-4af2-a9c9-9613606b53c6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97399cf0-ac3a-43c0-a7d7-fb56df5fc3dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8820d8b0-4749-4414-afbe-cbc3bc6146dd",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The person's name is Sarah Chen, and their most recent job is Senior Full Stack Developer at TechFlow Solutions.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm, similarity_top_k=5)\n",
    "response = query_engine.query(\"What is this person's name and what was their most recent job?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc5fbb0-e700-45d9-9e44-a6deae557a94",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "storage_dir = \"./storage\"\n",
    "\n",
    "index.storage_context.persist(persist_dir=storage_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0d88ae-c97d-42d9-a67c-1e3e846a4e11",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "733c762c-27d0-4bab-9a72-c5c0e568f9c4",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Check if the index is stored on disk\n",
    "if os.path.exists(storage_dir):\n",
    "    # Load the index from disk\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=storage_dir)\n",
    "    restored_index = load_index_from_storage(storage_context)\n",
    "else:\n",
    "    print(\"Index not found on disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "933e1172-2187-4847-a5a6-fca67eb9f1d6",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This person's name is Sarah Chen and their most recent job was as a Senior Full Stack Developer at TechFlow Solutions in San Francisco, CA.\n"
     ]
    }
   ],
   "source": [
    "response = restored_index.as_query_engine().query(\"What is this person's name and what was their most recent job?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f1ca1b-7e2f-416b-aa42-1adcd7d0fd53",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import FunctionCallingAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6837a256-7273-4a63-9f0b-2733a9f143d8",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "def query_resume(q: str) -> str:\n",
    "    \"\"\"Answers questions about a specific resume.\"\"\"\n",
    "    response = query_engine.query(f\"This is a question about the specific resume we have in our database: {q}\")\n",
    "    return response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "507c1f77-3f9c-4864-ae8c-2fcbc4f91a30",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "resume_tool = FunctionTool.from_defaults(fn=query_resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a2b4bb-f4ef-494a-af61-e12052706945",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "agent = FunctionCallingAgent.from_tools(\n",
    "    tools=[resume_tool],\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22722aa1-dcb0-4225-a16e-8ccdf254f288",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 7dcee0e6-7623-4901-a93d-4e9bc6d1358d. Step input: How many years of experience does the applicant have?\n",
      "Added user message to memory: How many years of experience does the applicant have?\n",
      "=== Calling Function ===\n",
      "Calling function: query_resume with args: {\"q\": \"How many years of experience does the applicant have?\"}\n",
      "=== Function Output ===\n",
      "The applicant has over 6 years of experience as a Full Stack Web Developer.\n",
      "> Running step 8d351f42-76fe-4952-ac5a-35f22526c293. Step input: None\n",
      "=== LLM Response ===\n",
      "The applicant has over 6 years of experience as a Full Stack Web Developer.\n",
      "The applicant has over 6 years of experience as a Full Stack Web Developer.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"How many years of experience does the applicant have?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "785f156c-9f06-4ea9-90cc-2f629fc7a7c8",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "659595b3-714f-441a-bd5b-84c36ea76367",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "class QueryEvent(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f76078-eb50-48d9-af22-47d5504e7e78",
   "metadata": {
    "height": 761
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> QueryEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            documents = LlamaParse(\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "        return QueryEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> StopEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return StopEvent(result=response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a06c2823-e2ae-4bc0-990d-e23707df7804",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first place the applicant worked is StartupHub in San Jose, CA.\n"
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=120, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    query=\"Where is the first place the applicant worked?\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "460b825b-d395-4c7a-ba78-635cddd4ff02",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.QueryEvent'>\n",
      "workflows/rag_workflow.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\"}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\"}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\"}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\"}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\"}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/rag_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
